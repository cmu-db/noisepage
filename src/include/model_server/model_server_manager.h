#pragma once

#include <filesystem>
#include <string>
#include "loggers/model_server_logger.h"
#include "messenger/messenger.h"
#include "messenger/messenger_defs.h"
#include "brain/brain_defs.h"

namespace noisepage::modelserver {
static constexpr const char *MODEL_CONN_ID_NAME = "model-server-conn";
static constexpr const char *MODEL_TARGET_NAME = "model";
static constexpr const char *MODEL_IPC_PATH = "/tmp/model-server-ipc";
static constexpr const char *MODEL_TCP_HOST = "127.0.0.1";
static constexpr const int MODEL_TCP_PORT = 15645;
static constexpr const int INVALID_PID = 0;

/*
 * Use 128 as convention to indicate failure in a subprocess:
 * https://www.gnu.org/software/libc/manual/html_node/Exit-Status.html
 */
static constexpr const unsigned char MODEL_ERROR_BINARY = 128;

/**
 * Interface for ModelServerManager related operations
 */
class ModelServerManager {
 public:
  /**
   * Construct a ModelServerManager with the given executable script to the python ModelServer
   * @param model_bin python script path
   * @param messenger Messenger pointer
   */
  ModelServerManager(const std::string &model_bin, const common::ManagedPointer<messenger::Messenger> &messenger);

  /**
   * Stop the python ModelServer when exits
   */
  ~ModelServerManager() { StopModelServer(); }

  /**
   * Stop the python-ModelServer daemon by sending a message to the Python model server
   */
  void StopModelServer();

  /**
   * Check if the model server has started.
   * The user of this function should poll this until the pid changes.
   * It is async because listening on the messenger's connector is now asynchronous.
   *
   * A true return value doesn't mean the model server script is running, but only guarantees
   * the fork() has succeeded.
   *
   * @return true if model server has started
   */
  bool ModelServerStarted() const { return py_pid_ != INVALID_PID; }

  /**
   * Get the python model-server's PID
   * @return  pid
   */
  pid_t GetModelPid() const { return py_pid_; }

  /*******************************************************
   * ModelServer <-> ModelServerManager logic routines
   *******************************************************/

  /**
   * Ask the model server to print a message
   * This function does not expect a callback
   *
   * @warning The message should not contain '-' as per current protocol
   * @param msg Message to print
   */
  void PrintMessage(const std::string &msg);

  /**
   * Train a model with the given seq files directory
   *
   * This function should expect a path to the saved model map
   * @param models list of candidates models that will be used for training
   * @param seq_files_dir Seq files's enclosing directory (seq files generated by mini_runner)
   * @bug Currently NOOP for callback
   */
  void TrainWith(const std::vector<std::string> &models, const std::string &seq_files_dir);

  /**
   * Perform inference on the given data file.
   *
   * This function should expect some return (Not figured out yet)
   * @param opunit Model for which to invoke
   * @param features Feature vectors
   * @return vector of results
   */
  void DoInference(brain::ExecutionOperatingUnitType opunit, const std::vector<std::vector<double>> &features);

 private:
  /**
   * This should be run as a thread routine.
   * 1. Make connection with the messenger
   * 2. Prepare arguments and forks to initialize a python daemon
   * 3. Record the pid
   */
  void StartModelServer(const std::string &model_path);

  static void ModelServerHandler(common::ManagedPointer<messenger::Messenger> messenger, std::string_view sender_id,
                                 std::string_view message, uint64_t recv_cb_id);

  std::string IPCPath() const { return MODEL_IPC_PATH; }
  std::string TCPPath() const { return fmt::format("{}:{}", MODEL_TCP_HOST, MODEL_TCP_PORT); }

  /** Messenger handler **/
  common::ManagedPointer<messenger::Messenger> messenger_;

  /** Connection router **/
  common::ManagedPointer<messenger::ConnectionRouter> router_;

  /** Thread the ModelServerManager runs in **/
  std::thread thd_;

  /** Python model pid **/
  pid_t py_pid_ = INVALID_PID;

  /** Bool shutting down **/
  bool shut_down_ = false;
};

}  // namespace noisepage::modelserver
